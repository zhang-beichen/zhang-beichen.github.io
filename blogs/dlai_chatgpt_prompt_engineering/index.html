<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Notes of ChatGPT Prompt Engineering for Developers | Beichen Zhang</title><meta name=keywords content="Large Language Models (LLMs),Natural Language Processing (NLP),DL"><meta name=description content="For ease of referring and checking in the future, I summarized this outline for the short course ChatGPT Prompt Engineering for Developers at DeepLearning.AI.
Introduction Introducing the general background of natural language process (NLP) with deep learning (DL).
Large language models (LLMs) [I think here the term refers to GPT-like LLMs] were categorized into two types.
Base LLM
Predicts the next word based on the training data Instruction Tuned LLM"><meta name=author content="Beichen Zhang"><link rel=canonical href=https://zhang-beichen.github.io/blogs/dlai_chatgpt_prompt_engineering/><link crossorigin=anonymous href=/assets/css/stylesheet.bc1149f4a72aa4858d3a9f71462f75e5884ffe8073ea9d6d5761d5663d651e20.css integrity="sha256-vBFJ9KcqpIWNOp9xRi915YhP/oBz6p1tV2HVZj1lHiA=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://zhang-beichen.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=https://zhang-beichen.github.io/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://zhang-beichen.github.io/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://zhang-beichen.github.io/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://zhang-beichen.github.io/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="Notes of ChatGPT Prompt Engineering for Developers"><meta property="og:description" content="For ease of referring and checking in the future, I summarized this outline for the short course ChatGPT Prompt Engineering for Developers at DeepLearning.AI.
Introduction Introducing the general background of natural language process (NLP) with deep learning (DL).
Large language models (LLMs) [I think here the term refers to GPT-like LLMs] were categorized into two types.
Base LLM
Predicts the next word based on the training data Instruction Tuned LLM"><meta property="og:type" content="article"><meta property="og:url" content="https://zhang-beichen.github.io/blogs/dlai_chatgpt_prompt_engineering/"><meta property="article:section" content="blogs"><meta property="article:published_time" content="2023-05-22T00:00:00+00:00"><meta property="article:modified_time" content="2023-05-22T00:00:00+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Notes of ChatGPT Prompt Engineering for Developers"><meta name=twitter:description content="For ease of referring and checking in the future, I summarized this outline for the short course ChatGPT Prompt Engineering for Developers at DeepLearning.AI.
Introduction Introducing the general background of natural language process (NLP) with deep learning (DL).
Large language models (LLMs) [I think here the term refers to GPT-like LLMs] were categorized into two types.
Base LLM
Predicts the next word based on the training data Instruction Tuned LLM"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Blogs","item":"https://zhang-beichen.github.io/blogs/"},{"@type":"ListItem","position":2,"name":"Notes of ChatGPT Prompt Engineering for Developers","item":"https://zhang-beichen.github.io/blogs/dlai_chatgpt_prompt_engineering/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Notes of ChatGPT Prompt Engineering for Developers","name":"Notes of ChatGPT Prompt Engineering for Developers","description":"For ease of referring and checking in the future, I summarized this outline for the short course ChatGPT Prompt Engineering for Developers at DeepLearning.AI.\nIntroduction Introducing the general background of natural language process (NLP) with deep learning (DL).\nLarge language models (LLMs) [I think here the term refers to GPT-like LLMs] were categorized into two types.\nBase LLM\nPredicts the next word based on the training data Instruction Tuned LLM","keywords":["Large Language Models (LLMs)","Natural Language Processing (NLP)","DL"],"articleBody":"For ease of referring and checking in the future, I summarized this outline for the short course ChatGPT Prompt Engineering for Developers at DeepLearning.AI.\nIntroduction Introducing the general background of natural language process (NLP) with deep learning (DL).\nLarge language models (LLMs) [I think here the term refers to GPT-like LLMs] were categorized into two types.\nBase LLM\nPredicts the next word based on the training data Instruction Tuned LLM\nTries to follow instructions (Fine-tuning based on instructions and making good attempts at following those instructions) RLHF: Reinforcement Learning with Human Feedback (arXiv paper) Helpful, Honest, Harmless [at least we hope so]\nThis short course comes with examples and practices on Jupyter Notebooks. I don’t think we can download them. So I organized and kept them in my GitHub repository.\nGuidelines Introducing two prompting principles and how to write effective prompts.\nPrinciple 1: Write clear and specific instructions\nAs clear and specific as possible. You don’t have to write short prompts. In many cases, longer prompts can provide more details to general, more relevant outputs. Skill 1: Use delimiters to clearly indicate distinct parts of the input (there is no limitation of delimiters, any punctuations that can separate the sentences will work). This can effectively reduce constructive instructions in the prompts. Skill 2: Ask for structured output (like HTML, JSON, etc.) Skill 3: Check whether conditions are satisfied. Check the assumptions required to do the task. (adding prompts to improve the consistency of outputs) Few shot prompting. Give successful examples of completing tasks. Then ask the model to perform the task. Principle 2: Give the model time to “think.”\nSkill 1: Specify the steps to complete a task. [step by step instructing] Skill 2: Instruct the model to work out its own solution before rushing to a conclusion. [ask the model to do step-by-step outputs.] Model Limitations: Hallucination: make statements that sound plausible but are not true. To address it, the suggestion is to find relevant information and then answer the question based on the relevant information. [However, personally, I think this might be too vague sometimes.]\nIterative: This is originally the third class. However, I think it is more like a trick or concept that can be applied to any use case. In plain language, we can continue updating and refining the prompts/instructions based on the outputs from the model. In the end, we can build prompts to let the model generate outputs closest to our expectations.\nApplications Summarizing: summarize text (with multiple objects) with a focus on specific topics. Similarly, you can “extract” information (named entity recognition) of multiple objects from the input text.\nInferring: infer sentiment and topics from product reviews and news articles, such as sentiment of the text, what types of emotions are reflected from the text, and extraction of objects ( similar to “extract” above).\nTransforming: language transformation tasks, such as language translation, spelling and grammar checking, tone adjustment, and format conversion.\nExpanding: generate text based on prompts specifying the requirement.\nChatbot: utilize the chat format to have extended conversations with chatbots personalized or specialized for specific tasks or behaviors.\n‘system’ role (high-level) can send ‘content’ to set the behavior of the assistant (chat model) to provide answers to the user (you) based on the prompts. System messages provide developers with a way to frame the conversation without making the requests a part of the conversation. Conclusion LLMs are very powerful. Please use them responsibly. Please only build things that will have a positive impact.\n","wordCount":"581","inLanguage":"en","datePublished":"2023-05-22T00:00:00Z","dateModified":"2023-05-22T00:00:00Z","author":{"@type":"Person","name":"Beichen Zhang"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://zhang-beichen.github.io/blogs/dlai_chatgpt_prompt_engineering/"},"publisher":{"@type":"Organization","name":"Beichen Zhang","logo":{"@type":"ImageObject","url":"https://zhang-beichen.github.io/%3Clink%20/%20abs%20url%3E"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://zhang-beichen.github.io/ accesskey=h title="Home (Alt + H)"><img src=https://zhang-beichen.github.io/apple-touch-icon.png alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://zhang-beichen.github.io/CV_Beichen_Zhang_2024March.pdf title="My CV"><span>My CV</span></a></li><li><a href=https://zhang-beichen.github.io/blogs/ title=Blogs><span>Blogs</span></a></li><li><a href=https://zhang-beichen.github.io/tags/ title=Tags><span>Tags</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class=post-title>Notes of ChatGPT Prompt Engineering for Developers</h1></header><div class=post-content><p>For ease of referring and checking in the future, I summarized this outline for the short course <em>ChatGPT Prompt Engineering for Developers</em> at <a href=https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/>DeepLearning.AI</a>.</p><h2 id=introduction>Introduction<a hidden class=anchor aria-hidden=true href=#introduction>#</a></h2><p>Introducing the general background of natural language process (NLP) with deep learning (DL).</p><ul><li><p>Large language models (LLMs) [I think here the term refers to GPT-like LLMs] were categorized into two types.</p></li><li><p>Base LLM</p></li><li><ul><li>Predicts the next word based on the training data</li></ul></li><li><p>Instruction Tuned LLM</p></li><li><ul><li><ul><li>Tries to follow instructions (Fine-tuning based on instructions and making good attempts at following those instructions)</li><li>RLHF: Reinforcement Learning with Human Feedback (<a href=https://arxiv.org/abs/2203.02155>arXiv paper</a>)</li></ul></li><li><p>Helpful, Honest, Harmless [at least we hope so]</p></li></ul></li><li><p>This short course comes with examples and practices on Jupyter Notebooks. I don&rsquo;t think we can download them. So I organized and kept them in my <a href=https://github.com/zhang-beichen/DLAI_ChatGPT_Prompt_Engineering>GitHub repository</a>.</p></li></ul><h2 id=guidelines>Guidelines<a hidden class=anchor aria-hidden=true href=#guidelines>#</a></h2><p>Introducing two prompting principles and how to write effective prompts.</p><ul><li><p><strong>Principle 1:</strong> Write clear and specific instructions</p></li><li><ul><li>As clear and specific as possible.</li><li>You don&rsquo;t have to write short prompts. In many cases, longer prompts can provide more details to general, more relevant outputs.</li><li><strong>Skill 1:</strong> <strong>Use delimiters to clearly indicate distinct parts of the input</strong> (there is no limitation of delimiters, any punctuations that can separate the sentences will work). This can effectively reduce constructive instructions in the prompts.</li><li><strong>Skill 2: Ask for structured output</strong> (like HTML, JSON, etc.)</li><li><strong>Skill 3: Check whether conditions are satisfied. Check the assumptions required to do the task.</strong> (adding prompts to improve the consistency of outputs)</li><li><strong>Few shot prompting</strong>. Give successful examples of completing tasks. Then ask the model to perform the task.</li></ul></li><li><p><strong>Principle 2</strong>: Give the model time to &ldquo;think.&rdquo;</p></li><li><ul><li><strong>Skill 1: Specify the steps to complete a task.</strong> [step by step instructing]</li><li><strong>Skill 2: Instruct the model to work out its own solution before rushing to a conclusion.</strong> [ask the model to do step-by-step outputs.]</li></ul></li><li><p><strong>Model Limitations</strong>: Hallucination: make statements that sound plausible but are not true. To address it, the suggestion is to find relevant information and then answer the question based on the relevant information. [However, personally, I think this might be too vague sometimes.]</p></li><li><p><strong>Iterative</strong>: This is originally the third class. However, I think it is more like a trick or concept that can be applied to any use case. In plain language, we can continue updating and refining the prompts/instructions based on the outputs from the model. In the end, we can build prompts to let the model generate outputs closest to our expectations.</p></li></ul><h2 id=applications>Applications<a hidden class=anchor aria-hidden=true href=#applications>#</a></h2><ul><li><p><strong>Summarizing</strong>: summarize text (with multiple objects) with a focus on specific topics. Similarly, you can &ldquo;<strong>extract</strong>&rdquo; information (named entity recognition) of multiple objects from the input text.</p></li><li><p><strong>Inferring</strong>: infer sentiment and topics from product reviews and news articles, such as sentiment of the text, what types of emotions are reflected from the text, and extraction of objects ( similar to &ldquo;extract&rdquo; above).</p></li><li><p><strong>Transforming</strong>: language transformation tasks, such as language translation, spelling and grammar checking, tone adjustment, and format conversion.</p></li><li><p><strong>Expanding</strong>: generate text based on prompts specifying the requirement.</p></li><li><p><strong>Chatbot</strong>: utilize the chat format to have extended conversations with chatbots personalized or specialized for specific tasks or behaviors.</p></li><li><ul><li>&lsquo;system&rsquo; role (high-level) can send &lsquo;content&rsquo; to set the behavior of the assistant (chat model) to provide answers to the user (you) based on the prompts. System messages provide developers with a way to frame the conversation without making the requests a part of the conversation.</li></ul></li></ul><h2 id=conclusion>Conclusion<a hidden class=anchor aria-hidden=true href=#conclusion>#</a></h2><p>LLMs are very powerful. Please use them responsibly. Please only build things that will have a positive impact.</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://zhang-beichen.github.io/tags/large-language-models-llms/>Large Language Models (LLMs)</a></li><li><a href=https://zhang-beichen.github.io/tags/natural-language-processing-nlp/>Natural Language Processing (NLP)</a></li><li><a href=https://zhang-beichen.github.io/tags/dl/>DL</a></li></ul><nav class=paginav><a class=prev href=https://zhang-beichen.github.io/blogs/agu2023/><span class=title>« Prev</span><br><span>AGU 2023 🌎</span></a>
<a class=next href=https://zhang-beichen.github.io/blogs/ams2023/><span class=title>Next »</span><br><span>AMS 2023 ⛅️</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2024 <a href=https://zhang-beichen.github.io/>Beichen Zhang</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>